Search.setIndex({docnames:["index","meguru_tokenizer","meguru_tokenizer.base_tokenizer","meguru_tokenizer.sentencepiece_tokenizer","meguru_tokenizer.vocab","meguru_tokenizer.whitespace_tokenizer","modules"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":3,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":1,"sphinx.ext.todo":2,"sphinx.ext.viewcode":1,sphinx:56},filenames:["index.rst","meguru_tokenizer.rst","meguru_tokenizer.base_tokenizer.rst","meguru_tokenizer.sentencepiece_tokenizer.rst","meguru_tokenizer.vocab.rst","meguru_tokenizer.whitespace_tokenizer.rst","modules.rst"],objects:{"":{meguru_tokenizer:[1,0,0,"-"]},"meguru_tokenizer.Tokenizer":{decode:[1,2,1,""],encode:[1,2,1,""],languages:[1,3,1,""],tokenize:[1,2,1,""],tokenize_list:[1,2,1,""],vocab_size:[1,2,1,""]},"meguru_tokenizer.base_tokenizer":{Tokenizer:[2,1,1,""]},"meguru_tokenizer.base_tokenizer.Tokenizer":{decode:[2,2,1,""],encode:[2,2,1,""],languages:[2,3,1,""],tokenize:[2,2,1,""],tokenize_list:[2,2,1,""],vocab_size:[2,2,1,""]},"meguru_tokenizer.sentencepiece_tokenizer":{SentencePieceTokenizer:[3,1,1,""]},"meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer":{decode:[3,2,1,""],encode:[3,2,1,""],languages:[3,3,1,""],load_sp_model:[3,2,1,""],tokenize:[3,2,1,""],tokenize_list:[3,2,1,""],train_sp:[3,2,1,""],vocab_size:[3,2,1,""]},"meguru_tokenizer.vocab":{Vocab:[4,1,1,""]},"meguru_tokenizer.vocab.Vocab":{add_vocab:[4,2,1,""],add_vocabs:[4,2,1,""],build_vocab:[4,2,1,""],dump_vocab:[4,2,1,""],idx2word:[4,2,1,""],load_vocab:[4,2,1,""],word2idx:[4,2,1,""]},"meguru_tokenizer.whitespace_tokenizer":{WhitespaceTokenizer:[5,1,1,""]},"meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer":{decode:[5,2,1,""],encode:[5,2,1,""],languages:[5,3,1,""],tokenize:[5,2,1,""],tokenize_list:[5,2,1,""],vocab_size:[5,2,1,""]},meguru_tokenizer:{Tokenizer:[1,1,1,""],base_tokenizer:[2,0,0,"-"],sentencepiece_tokenizer:[3,0,0,"-"],vocab:[4,0,0,"-"],whitespace_tokenizer:[5,0,0,"-"]}},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","attribute","Python attribute"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:attribute"},terms:{"\u304a\u306f\u3088\u3046":[1,2,3,5],"\u304a\u306f\u3088\u3046\u3054\u3056\u3044\u307e\u3059":[1,2,3,5],"\u3054\u3056\u3044":[1,2,3,5],"abstract":[1,2],"char":3,"class":[1,2,3,4,5],"default":3,"float":3,"import":5,"int":[1,2,3,4,5],"return":[1,2,3,4,5],"true":[3,5],"while":3,abc:[1,2],add:4,add_vocab:[4,5],added:4,assert:3,attribut:[1,2],awesom:[3,5],base:[1,2,3,4,5],base_token:[0,1,3,5,6],bool:[1,2,3,5],bos:4,bpe:3,build:4,build_vocab:[4,5],charact:3,character_coverag:3,com:3,construct:4,content:[0,6],coverag:3,decod:[1,2,3,5],don:[3,5],dump:[3,4],dump_vocab:[4,5],encod:[1,2,3,5],englishwhitespacetoken:5,eos:4,exampl:[1,2,3,4,5],export_path:4,extra_vocab:4,file:3,found:4,framework:[3,5],free:4,frequenc:4,from:[3,4],github:3,good:[3,5],googl:3,hello:[3,5],how:[3,5],http:3,i2w:5,idx2word:4,idx:[3,4],index:[0,4],know:[3,5],languag:[1,2,3,5],line:3,list:[1,2,3,4,5],load_path:4,load_sp_model:3,load_vocab:4,lower:[1,2,3,5],mask:[3,4,5],maximum:4,mecab:[1,2],memori:4,min_freq:4,minimum:4,model:3,model_prefix:3,model_typ:3,modul:[0,6],none:[3,4,5],normal:[1,2,3,5],object:4,open:3,option:[4,5],packag:[0,6],pad:[3,4,5],page:0,pair:4,param:[1,2,3,5],paramet:[1,2,3,4,5],path:[3,4,5],pathlib:4,per:3,pprint:5,pre_defined_symbol:3,prefix:3,pretoken:3,print:[3,5],readlin:3,ref:3,reload:3,remov:4,resource_fil:3,resource_flil:3,search:0,sentenc:[1,2,3,4,5],sentencepiec:3,sentencepiece_token:[0,1,6],sentencepieceprocessor:3,sentencepiecetoken:3,sentnec:[1,2,3,5],size:[1,2,3,4,5],sourc:[1,2,3,4,5],source_fil:3,space:4,special:3,split:[3,4,5],str:[1,2,3,4,5],strip:3,submodul:[0,6],sudachi:[1,2],tensorflow:[3,5],test:3,token:[1,2,3,5],tokenize_list:[1,2,3,5],train:3,train_sp:3,txt:[3,5],type:[1,2,3,4,5],unigram:3,unk:[1,2,3,4,5],use:[3,5],user_defined_symbol:3,utf:3,vocab:[0,1,3,5,6],vocab_s:[1,2,3,4,5],vocaburari:[1,2,3,4,5],when:4,which:4,whitespac:5,whitespace_token:[0,1,6],whitespacetoken:5,word2idx:4,word:[1,2,3,4,5],write:3},titles:["Welcome to meguru_tokenizer\u2019s documentation!","meguru_tokenizer package","meguru_tokenizer.base_tokenizer module","meguru_tokenizer.sentencepiece_tokenizer module","meguru_tokenizer.vocab module","meguru_tokenizer.whitespace_tokenizer module","meguru_tokenizer"],titleterms:{base_token:2,content:1,document:0,indic:0,meguru_token:[0,1,2,3,4,5,6],modul:[1,2,3,4,5],packag:1,sentencepiece_token:3,submodul:1,tabl:0,vocab:4,welcom:0,whitespace_token:5}})