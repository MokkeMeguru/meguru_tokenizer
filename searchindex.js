Search.setIndex({docnames:["index","meguru_tokenizer","meguru_tokenizer.base_tokenizer","meguru_tokenizer.sentencepiece_tokenizer","meguru_tokenizer.vocab","meguru_tokenizer.whitespace_tokenizer","modules"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":2,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":2,"sphinx.domains.rst":2,"sphinx.domains.std":1,"sphinx.ext.todo":2,"sphinx.ext.viewcode":1,sphinx:56},filenames:["index.rst","meguru_tokenizer.rst","meguru_tokenizer.base_tokenizer.rst","meguru_tokenizer.sentencepiece_tokenizer.rst","meguru_tokenizer.vocab.rst","meguru_tokenizer.whitespace_tokenizer.rst","modules.rst"],objects:{},objnames:{},objtypes:{},terms:{base_token:[0,1,6],content:[0,6],index:0,modul:[0,6],packag:[0,6],page:0,search:0,sentencepiece_token:[0,1,6],submodul:[0,6],vocab:[0,1,6],whitespace_token:[0,1,6]},titles:["Welcome to meguru_tokenizer\u2019s documentation!","meguru_tokenizer package","meguru_tokenizer.base_tokenizer module","meguru_tokenizer.sentencepiece_tokenizer module","meguru_tokenizer.vocab module","meguru_tokenizer.whitespace_tokenizer module","meguru_tokenizer"],titleterms:{base_token:2,content:1,document:0,indic:0,meguru_token:[0,1,2,3,4,5,6],modul:[1,2,3,4,5],packag:1,sentencepiece_token:3,submodul:1,tabl:0,vocab:4,welcom:0,whitespace_token:5}})