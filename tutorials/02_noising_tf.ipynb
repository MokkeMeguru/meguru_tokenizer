{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Noising (Masking) for Tensorflow 2.x\n",
    "\n",
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('tenosrflow', '2.2.0', 'tokenizer', '0.1.0')"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import neologdn\n",
    "import tensorflow as tf\n",
    "\n",
    "import meguru_tokenizer\n",
    "from meguru_tokenizer.whitespace_tokenizer import WhitespaceTokenizer\n",
    "from meguru_tokenizer.vocab import Vocab\n",
    "from meguru_tokenizer.process.noise_tf import Noiser\n",
    "\n",
    "\"tenosrflow\", tf.__version__, \"tokenizer\", meguru_tokenizer.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Hello, I don't know how to use it?\",\n",
    "    \"Tensorflow is awesome!\",\n",
    "    \"It is good framework.\",\n",
    "]\n",
    "\n",
    "with Path(\"source.txt\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences:\n",
    "        f.write(sentence + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Hello, I don't know how to use it?\nTensorflow is awesome!\nIt is good framework.\n"
    }
   ],
   "source": [
    "!cat source.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Tokenizer, Vocaburary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhitespaceTokenizer(lower=True, language=\"en\")\n",
    "vocab = Vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "building vocaburary from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'<pad>': 0,\n '<s>': 1,\n '</s>': 2,\n '<unk>': 3,\n '<mask>': 4,\n 'it': 5,\n 'is': 6,\n 'hello': 7,\n ',': 8,\n 'i': 9,\n 'do': 10,\n \"n't\": 11,\n 'know': 12,\n 'how': 13,\n 'to': 14,\n 'use': 15,\n '?': 16,\n 'tensorflow': 17,\n 'awesome': 18,\n '!': 19,\n 'good': 20,\n 'framework': 21,\n '.': 22}"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    vocab.add_vocabs(tokenizer.tokenize(sentence))\n",
    "vocab.build_vocab(vocab_size=30)\n",
    "\n",
    "tokenizer.vocab = vocab\n",
    "noiser = Noiser(vocab=tokenizer.vocab)\n",
    "\n",
    "vocab.w2i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump & load vocaburary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'<pad>': 0,\n '<s>': 1,\n '</s>': 2,\n '<unk>': 3,\n '<mask>': 4,\n 'it': 5,\n 'is': 6,\n 'hello': 7,\n ',': 8,\n 'i': 9,\n 'do': 10,\n \"n't\": 11,\n 'know': 12,\n 'how': 13,\n 'to': 14,\n 'use': 15,\n '?': 16,\n 'tensorflow': 17,\n 'awesome': 18,\n '!': 19,\n 'good': 20,\n 'framework': 21,\n '.': 22}"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "vocab.dump_vocab(Path(\"vocab.txt\"))\n",
    "\n",
    "vocab = Vocab()\n",
    "vocab.load_vocab(Path(\"vocab.txt\"))\n",
    "vocab.w2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bos id  1\n"
    }
   ],
   "source": [
    "ds = tf.data.TextLineDataset(\"source.txt\")\n",
    "bos_id = tokenizer.vocab.word2idx(tokenizer.vocab.bos)\n",
    "print(\"bos id \", bos_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup text enoder\n",
    "\n",
    "80 % word masking (blanking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    encoded_text = tokenizer.encode(text.numpy().decode())\n",
    "    encoded_text = noiser.noisy(encoded_text, drop_prob=0.0, blank_prob=0.8, sub_prob=0.0, shuffle_dist=0.0)\n",
    "    print(\n",
    "        \"[noised]\\n\",\n",
    "        encoded_text,\n",
    "        \"\\n\",\n",
    "        text.numpy().decode(),\n",
    "        \"->\",\n",
    "        tokenizer.decode(np.concatenate(([bos_id], encoded_text))),\n",
    "    )\n",
    "    return np.concatenate(([bos_id], encoded_text))\n",
    "\n",
    "def encoded_map_fn(text):\n",
    "    encoded_text = tf.py_function(encode, inp=[text], Tout=(tf.int64))\n",
    "    encoded_text.set_shape([None])\n",
    "    return encoded_text\n",
    "\n",
    "encoded_ds = ds.map(encoded_map_fn).padded_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch : 0\n[noised]\n [4 4 4 4 4 4 4 4 4 4 4] \n Hello, I don't know how to use it? -> <s> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask>\n[noised]\n [4 4 4 4] \n Tensorflow is awesome! -> <s> <mask> <mask> <mask> <mask>\n[noised]\n [ 4  4  4 21  4] \n It is good framework. -> <s> <mask> <mask> <mask> framework <mask>\n[padded batch]\ntf.Tensor(\n[[ 1  4  4  4  4  4  4  4  4  4  4  4]\n [ 1  4  4  4  4  0  0  0  0  0  0  0]\n [ 1  4  4  4 21  4  0  0  0  0  0  0]], shape=(3, 12), dtype=int64)\nepoch : 1\n[noised]\n [ 4  4  4 10  4  4  4  4 15  4  4] \n Hello, I don't know how to use it? -> <s> <mask> <mask> <mask> do <mask> <mask> <mask> <mask> use <mask> <mask>\n[noised]\n [4 4 4 4] \n Tensorflow is awesome! -> <s> <mask> <mask> <mask> <mask>\n[noised]\n [4 4 4 4 4] \n It is good framework. -> <s> <mask> <mask> <mask> <mask> <mask>\n[padded batch]\ntf.Tensor(\n[[ 1  4  4  4 10  4  4  4  4 15  4  4]\n [ 1  4  4  4  4  0  0  0  0  0  0  0]\n [ 1  4  4  4  4  4  0  0  0  0  0  0]], shape=(3, 12), dtype=int64)\nepoch : 2\n[noised]\n [4 8 4 4 4 4 4 4 4 4 4] \n Hello, I don't know how to use it? -> <s> <mask> , <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask> <mask>\n[noised]\n [4 4 4 4] \n Tensorflow is awesome! -> <s> <mask> <mask> <mask> <mask>\n[noised]\n [4 4 4 4 4] \n It is good framework. -> <s> <mask> <mask> <mask> <mask> <mask>\n[padded batch]\ntf.Tensor(\n[[1 4 8 4 4 4 4 4 4 4 4 4]\n [1 4 4 4 4 0 0 0 0 0 0 0]\n [1 4 4 4 4 4 0 0 0 0 0 0]], shape=(3, 12), dtype=int64)\n"
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    print(\"epoch :\", epoch)\n",
    "    for batch in encoded_ds:\n",
    "        print(\"[padded batch]\")\n",
    "        print(batch)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bit377pyenv620b0b1b32ab4397bc065e9064a3b00c",
   "display_name": "Python 3.7.7 64-bit ('3.7.7': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}