


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; meguru_tokenizer 0.1.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> meguru_tokenizer
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="meguru_tokenizer.html">meguru_tokenizer package</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">meguru_tokenizer</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Index</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 
</div>
<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.add_vocab">add_vocab() (meguru_tokenizer.vocab.Vocab method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.add_vocabs">add_vocabs() (meguru_tokenizer.vocab.Vocab method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.BaseVocab">BaseVocab (class in meguru_tokenizer.vocab)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.build_vocab">build_vocab() (meguru_tokenizer.vocab.Vocab method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.decode">decode() (meguru_tokenizer.base_tokenizer.Tokenizer method)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.decode">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.decode">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.decode">(meguru_tokenizer.Tokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.decode">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.dump_vocab">dump_vocab() (meguru_tokenizer.vocab.Vocab method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.encode">encode() (meguru_tokenizer.base_tokenizer.Tokenizer method)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.encode">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.encode">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.encode">(meguru_tokenizer.Tokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.encode">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceVocab.idx2word">idx2word() (meguru_tokenizer.sentencepiece_tokenizer.SentencePieceVocab method)</a>

      <ul>
        <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.BaseVocab.idx2word">(meguru_tokenizer.vocab.BaseVocab method)</a>
</li>
        <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.idx2word">(meguru_tokenizer.vocab.Vocab method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.languages">languages (meguru_tokenizer.base_tokenizer.Tokenizer attribute)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.languages">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer attribute)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.languages">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer attribute)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.languages">(meguru_tokenizer.Tokenizer attribute)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.LooseWhitespaceTokenizer.languages">(meguru_tokenizer.whitespace_tokenizer.LooseWhitespaceTokenizer attribute)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.languages">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.load_sp_model">load_sp_model() (meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.load_vocab">load_vocab() (meguru_tokenizer.vocab.Vocab method)</a>
</li>
      <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.LooseWhitespaceTokenizer">LooseWhitespaceTokenizer (class in meguru_tokenizer.whitespace_tokenizer)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    meguru_tokenizer

      <ul>
        <li><a href="meguru_tokenizer.html#module-meguru_tokenizer">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.base_tokenizer

      <ul>
        <li><a href="meguru_tokenizer.base_tokenizer.html#module-meguru_tokenizer.base_tokenizer">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.process

      <ul>
        <li><a href="meguru_tokenizer.process.html#module-meguru_tokenizer.process">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.process.noise_pytorch

      <ul>
        <li><a href="meguru_tokenizer.process.noise_pytorch.html#module-meguru_tokenizer.process.noise_pytorch">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.process.noise_tf

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#module-meguru_tokenizer.process.noise_tf">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.sentencepiece_tokenizer

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#module-meguru_tokenizer.sentencepiece_tokenizer">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.sudachi_tokenizer

      <ul>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#module-meguru_tokenizer.sudachi_tokenizer">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    meguru_tokenizer.vocab

      <ul>
        <li><a href="meguru_tokenizer.vocab.html#module-meguru_tokenizer.vocab">module</a>
</li>
      </ul></li>
      <li>
    meguru_tokenizer.whitespace_tokenizer

      <ul>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#module-meguru_tokenizer.whitespace_tokenizer">module</a>
</li>
      </ul></li>
      <li>
    module

      <ul>
        <li><a href="meguru_tokenizer.html#module-meguru_tokenizer">meguru_tokenizer</a>
</li>
        <li><a href="meguru_tokenizer.base_tokenizer.html#module-meguru_tokenizer.base_tokenizer">meguru_tokenizer.base_tokenizer</a>
</li>
        <li><a href="meguru_tokenizer.process.html#module-meguru_tokenizer.process">meguru_tokenizer.process</a>
</li>
        <li><a href="meguru_tokenizer.process.noise_pytorch.html#module-meguru_tokenizer.process.noise_pytorch">meguru_tokenizer.process.noise_pytorch</a>
</li>
        <li><a href="meguru_tokenizer.process.noise_tf.html#module-meguru_tokenizer.process.noise_tf">meguru_tokenizer.process.noise_tf</a>
</li>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#module-meguru_tokenizer.sentencepiece_tokenizer">meguru_tokenizer.sentencepiece_tokenizer</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#module-meguru_tokenizer.sudachi_tokenizer">meguru_tokenizer.sudachi_tokenizer</a>
</li>
        <li><a href="meguru_tokenizer.vocab.html#module-meguru_tokenizer.vocab">meguru_tokenizer.vocab</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#module-meguru_tokenizer.whitespace_tokenizer">meguru_tokenizer.whitespace_tokenizer</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser">Noiser (class in meguru_tokenizer.process.noise_pytorch)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser">(class in meguru_tokenizer.process.noise_tf)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser.noisy">noisy() (meguru_tokenizer.process.noise_pytorch.Noiser method)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser.noisy">(meguru_tokenizer.process.noise_tf.Noiser method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer">SentencePieceTokenizer (class in meguru_tokenizer.sentencepiece_tokenizer)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceVocab">SentencePieceVocab (class in meguru_tokenizer.sentencepiece_tokenizer)</a>
</li>
      <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer">SudachiTokenizer (class in meguru_tokenizer.sudachi_tokenizer)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.tokenize">tokenize() (meguru_tokenizer.base_tokenizer.Tokenizer method)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.tokenize">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.tokenize">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.tokenize">(meguru_tokenizer.Tokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.LooseWhitespaceTokenizer.tokenize">(meguru_tokenizer.whitespace_tokenizer.LooseWhitespaceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.tokenize">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer method)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.tokenize_list">tokenize_list() (meguru_tokenizer.base_tokenizer.Tokenizer method)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.tokenize_list">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.tokenize_list">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.tokenize_list">(meguru_tokenizer.Tokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.tokenize_list">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer">Tokenizer (class in meguru_tokenizer)</a>

      <ul>
        <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer">(class in meguru_tokenizer.base_tokenizer)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.tokenizer">tokenizer (meguru_tokenizer.base_tokenizer.Tokenizer attribute)</a>

      <ul>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.tokenizer">(meguru_tokenizer.Tokenizer attribute)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.train_sp">train_sp() (meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab">Vocab (class in meguru_tokenizer.vocab)</a>
</li>
      <li><a href="meguru_tokenizer.base_tokenizer.html#meguru_tokenizer.base_tokenizer.Tokenizer.vocab_size">vocab_size() (meguru_tokenizer.base_tokenizer.Tokenizer method)</a>

      <ul>
        <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer.vocab_size">(meguru_tokenizer.sentencepiece_tokenizer.SentencePieceTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.sudachi_tokenizer.html#meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer.vocab_size">(meguru_tokenizer.sudachi_tokenizer.SudachiTokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.html#meguru_tokenizer.Tokenizer.vocab_size">(meguru_tokenizer.Tokenizer method)</a>
</li>
        <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer.vocab_size">(meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.whitespace_tokenizer.html#meguru_tokenizer.whitespace_tokenizer.WhitespaceTokenizer">WhitespaceTokenizer (class in meguru_tokenizer.whitespace_tokenizer)</a>
</li>
      <li><a href="meguru_tokenizer.sentencepiece_tokenizer.html#meguru_tokenizer.sentencepiece_tokenizer.SentencePieceVocab.word2idx">word2idx() (meguru_tokenizer.sentencepiece_tokenizer.SentencePieceVocab method)</a>

      <ul>
        <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.BaseVocab.word2idx">(meguru_tokenizer.vocab.BaseVocab method)</a>
</li>
        <li><a href="meguru_tokenizer.vocab.html#meguru_tokenizer.vocab.Vocab.word2idx">(meguru_tokenizer.vocab.Vocab method)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser.word_blank">word_blank() (meguru_tokenizer.process.noise_pytorch.Noiser method)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser.word_blank">(meguru_tokenizer.process.noise_tf.Noiser method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser.word_drop">word_drop() (meguru_tokenizer.process.noise_pytorch.Noiser method)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser.word_drop">(meguru_tokenizer.process.noise_tf.Noiser method)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser.word_shuffle">word_shuffle() (meguru_tokenizer.process.noise_pytorch.Noiser method)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser.word_shuffle">(meguru_tokenizer.process.noise_tf.Noiser method)</a>
</li>
      </ul></li>
      <li><a href="meguru_tokenizer.process.noise_pytorch.html#meguru_tokenizer.process.noise_pytorch.Noiser.word_substitute">word_substitute() (meguru_tokenizer.process.noise_pytorch.Noiser method)</a>

      <ul>
        <li><a href="meguru_tokenizer.process.noise_tf.html#meguru_tokenizer.process.noise_tf.Noiser.word_substitute">(meguru_tokenizer.process.noise_tf.Noiser method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>



           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, MokkeMeguru

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>